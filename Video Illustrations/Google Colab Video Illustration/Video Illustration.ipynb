{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"17PhUPbLsH1n7BHNRc1Io6CHeQGOTVBqj","authorship_tag":"ABX9TyNYFKcO0vtTgEEULFvcpUAa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!cd Final\\ Project\\ on\\ CUDA"],"metadata":{"id":"ilLg5GXhHiMZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733760994910,"user_tz":300,"elapsed":281,"user":{"displayName":"Tanvi Virappa Patil","userId":"04359576273509452367"}},"outputId":"26593627-bf96-40f5-c36b-42f96196672c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: cd: Final Project on CUDA: No such file or directory\n"]}]},{"cell_type":"code","source":["from IPython.display import display, Javascript,HTML\n","from google.colab.output import eval_js\n","from base64 import b64decode"],"metadata":{"id":"QEkH1VU11ouk","executionInfo":{"status":"ok","timestamp":1733760995202,"user_tz":300,"elapsed":10,"user":{"displayName":"Tanvi Virappa Patil","userId":"04359576273509452367"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["global video_path;\n","\n","def record_video(filename):\n","  js=Javascript(\"\"\"\n","    async function recordVideo() {\n","      const options = { mimeType: \"video/webm; codecs=vp9\" };\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      const stopCapture = document.createElement(\"button\");\n","\n","      capture.textContent = \"Start Recording\";\n","      capture.style.background = \"orange\";\n","      capture.style.color = \"white\";\n","\n","      stopCapture.textContent = \"Stop Recording\";\n","      stopCapture.style.background = \"red\";\n","      stopCapture.style.color = \"white\";\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      const recordingVid = document.createElement(\"video\");\n","      video.style.display = 'block';\n","\n","      const stream = await navigator.mediaDevices.getUserMedia({audio:true, video: true});\n","\n","      let recorder = new MediaRecorder(stream, options);\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","\n","      video.srcObject = stream;\n","      video.muted = true;\n","\n","      await video.play();\n","\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      await new Promise((resolve) => {\n","        capture.onclick = resolve;\n","      });\n","      recorder.start();\n","      capture.replaceWith(stopCapture);\n","\n","      await new Promise((resolve) => stopCapture.onclick = resolve);\n","      recorder.stop();\n","      let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n","      let arrBuff = await recData.data.arrayBuffer();\n","\n","      // stop the stream and remove the video element\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","\n","      let binaryString = \"\";\n","      let bytes = new Uint8Array(arrBuff);\n","      bytes.forEach((byte) => {\n","        binaryString += String.fromCharCode(byte);\n","      })\n","    return btoa(binaryString);\n","    }\n","  \"\"\")\n","  try:\n","    display(js)\n","    data=eval_js('recordVideo({})')\n","    binary=b64decode(data)\n","    with open(filename,\"wb\") as video_file:\n","      video_file.write(binary)\n","    print(f\"Finished recording video at:{filename}\")\n","  except Exception as err:\n","    print(str(err))"],"metadata":{"id":"w5-1L6UO1oul","executionInfo":{"status":"ok","timestamp":1733760995203,"user_tz":300,"elapsed":10,"user":{"displayName":"Tanvi Virappa Patil","userId":"04359576273509452367"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from IPython.display import HTML\n","from base64 import b64encode\n","\n","def show_video(video_path, video_width = 600):\n","\n","  video_file = open(video_path, \"r+b\").read()\n","\n","  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n","  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")"],"metadata":{"id":"kWyP8bkRG87f","executionInfo":{"status":"ok","timestamp":1733760995203,"user_tz":300,"elapsed":9,"user":{"displayName":"Tanvi Virappa Patil","userId":"04359576273509452367"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["video_path = \"test.mp4\"\n","record_video(video_path)"],"metadata":{"id":"HhmrwhcHHMq3","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1733761022485,"user_tz":300,"elapsed":27291,"user":{"displayName":"Tanvi Virappa Patil","userId":"04359576273509452367"}},"outputId":"1aafd204-1078-48ea-f7e8-dfd82947c829"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function recordVideo() {\n","      const options = { mimeType: \"video/webm; codecs=vp9\" };\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      const stopCapture = document.createElement(\"button\");\n","\n","      capture.textContent = \"Start Recording\";\n","      capture.style.background = \"orange\";\n","      capture.style.color = \"white\";\n","\n","      stopCapture.textContent = \"Stop Recording\";\n","      stopCapture.style.background = \"red\";\n","      stopCapture.style.color = \"white\";\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      const recordingVid = document.createElement(\"video\");\n","      video.style.display = 'block';\n","\n","      const stream = await navigator.mediaDevices.getUserMedia({audio:true, video: true});\n","\n","      let recorder = new MediaRecorder(stream, options);\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","\n","      video.srcObject = stream;\n","      video.muted = true;\n","\n","      await video.play();\n","\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      await new Promise((resolve) => {\n","        capture.onclick = resolve;\n","      });\n","      recorder.start();\n","      capture.replaceWith(stopCapture);\n","\n","      await new Promise((resolve) => stopCapture.onclick = resolve);\n","      recorder.stop();\n","      let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n","      let arrBuff = await recData.data.arrayBuffer();\n","\n","      // stop the stream and remove the video element\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","\n","      let binaryString = \"\";\n","      let bytes = new Uint8Array(arrBuff);\n","      bytes.forEach((byte) => {\n","        binaryString += String.fromCharCode(byte);\n","      })\n","    return btoa(binaryString);\n","    }\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Finished recording video at:test.mp4\n"]}]},{"cell_type":"code","source":["cuda_code = '''\n","#include <opencv2/opencv.hpp>\n","#include <cuda_runtime.h>\n","#include <iostream>\n","#include <vector>\n","#include <cmath>\n","\n","// Constants\n","#define BLOCK_SIZE 16\n","#define COEFF 0.5f             // Smaller coefficient for sharper edge differentiation\n","#define THRESHOLD_VALUE 0.05f  // Adaptive thresholding used below\n","\n","// CUDA kernel for horizontal Gaussian blur\n","__global__ void gaussianBlurHorizontal(const float* input, float* output, int width, int height, const float* kernel, int kernelSize) {\n","    int x = blockIdx.x * blockDim.x + threadIdx.x;\n","    int y = blockIdx.y * blockDim.y + threadIdx.y;\n","\n","    if (x >= width || y >= height) return;\n","\n","    float sum = 0.0f;\n","    int halfKernel = kernelSize / 2;\n","    for (int i = -halfKernel; i <= halfKernel; ++i) {\n","        int neighborX = min(max(x + i, 0), width - 1);\n","        sum += input[y * width + neighborX] * kernel[halfKernel + i];\n","    }\n","    output[y * width + x] = sum;\n","}\n","\n","// CUDA kernel for vertical Gaussian blur\n","__global__ void gaussianBlurVertical(const float* input, float* output, int width, int height, const float* kernel, int kernelSize) {\n","    int x = blockIdx.x * blockDim.x + threadIdx.x;\n","    int y = blockIdx.y * blockDim.y + threadIdx.y;\n","\n","    if (x >= width || y >= height) return;\n","\n","    float sum = 0.0f;\n","    int halfKernel = kernelSize / 2;\n","    for (int i = -halfKernel; i <= halfKernel; ++i) {\n","        int neighborY = min(max(y + i, 0), height - 1);\n","        sum += input[neighborY * width + x] * kernel[halfKernel + i];\n","    }\n","    output[y * width + x] = sum;\n","}\n","\n","// CUDA kernel for computing illustration differences\n","__global__ void computeIllustration(const float* original, const float* blurred, float* output, int width, int height, float coeff) {\n","    int x = blockIdx.x * blockDim.x + threadIdx.x;\n","    int y = blockIdx.y * blockDim.y + threadIdx.y;\n","\n","    if (x >= width || y >= height) return;\n","\n","    int idx = y * width + x;\n","    float diff = (original[idx] - blurred[idx]) / (coeff + original[idx]);\n","    output[idx] += diff;\n","}\n","\n","// CUDA kernel for smooth thresholding\n","__global__ void applySmoothThreshold(const float* input, float* output, int width, int height, float threshold) {\n","    int x = blockIdx.x * blockDim.x + threadIdx.x;\n","    int y = blockIdx.y * blockDim.y + threadIdx.y;\n","\n","    if (x >= width || y >= height) return;\n","\n","    int idx = y * width + x;\n","    float value = input[idx];\n","    // Sigmoid function for smooth thresholding\n","    output[idx] = 1.0f / (1.0f + expf(-10.0f * (value - threshold)));\n","}\n","\n","// Generate Gaussian kernel\n","void generateGaussianKernel(std::vector<float>& kernel, int size, float alpha) {\n","    int halfSize = size / 2;\n","    float sum = 0.0f;\n","    for (int i = -halfSize; i <= halfSize; ++i) {\n","        float value = expf(-(i * i) / (2.0f * alpha * alpha));\n","        kernel[halfSize + i] = value;\n","        sum += value;\n","    }\n","    for (float& v : kernel) v /= sum;\n","}\n","\n","// Function to process a single frame\n","void processFrame(const float* src, float* dest, int width, int height, int levels, int frameCount, float adaptiveThreshold) {\n","    size_t imageSize = width * height * sizeof(float);\n","\n","    // Device memory allocation\n","    float *d_original, *d_blurred, *d_temp, *d_output, *d_kernel;\n","    cudaMalloc(&d_original, imageSize);\n","    cudaMalloc(&d_blurred, imageSize);\n","    cudaMalloc(&d_temp, imageSize);\n","    cudaMalloc(&d_output, imageSize);\n","    cudaMemcpy(d_original, src, imageSize, cudaMemcpyHostToDevice);\n","    cudaMemset(d_output, 0, imageSize);\n","\n","    dim3 threads(BLOCK_SIZE, BLOCK_SIZE);\n","    dim3 blocks((width + BLOCK_SIZE - 1) / BLOCK_SIZE, (height + BLOCK_SIZE - 1) / BLOCK_SIZE);\n","\n","    for (int s = 1; s <= levels; ++s) {\n","        float alpha = pow(1.6f, s);\n","        int kernelSize = ceil(3 * alpha) * 2 + 1;\n","\n","        // Generate Gaussian kernel\n","        std::vector<float> h_kernel(kernelSize);\n","        generateGaussianKernel(h_kernel, kernelSize, alpha);\n","        cudaMalloc(&d_kernel, kernelSize * sizeof(float));\n","        cudaMemcpy(d_kernel, h_kernel.data(), kernelSize * sizeof(float), cudaMemcpyHostToDevice);\n","\n","        // Apply horizontal and vertical Gaussian blur\n","        gaussianBlurHorizontal<<<blocks, threads>>>(d_original, d_temp, width, height, d_kernel, kernelSize);\n","        cudaDeviceSynchronize();\n","        gaussianBlurVertical<<<blocks, threads>>>(d_temp, d_blurred, width, height, d_kernel, kernelSize);\n","        cudaDeviceSynchronize();\n","\n","        // Save intermediate blurred frame for debugging\n","        if (s == 1) {\n","            std::vector<float> blurredFrame(width * height);\n","            cudaMemcpy(blurredFrame.data(), d_blurred, imageSize, cudaMemcpyDeviceToHost);\n","            cv::Mat intermediateBlur(height, width, CV_32F, blurredFrame.data());\n","            intermediateBlur.convertTo(intermediateBlur, CV_8U, 255.0);\n","            //cv::imwrite(\"debug_blurred_frame_\" + std::to_string(frameCount) + \".png\", intermediateBlur);\n","        }\n","\n","        // Compute illustration differences\n","        computeIllustration<<<blocks, threads>>>(d_original, d_blurred, d_output, width, height, COEFF);\n","        cudaDeviceSynchronize();\n","\n","        // Swap the blurred image for the next iteration\n","        cudaMemcpy(d_original, d_blurred, imageSize, cudaMemcpyDeviceToDevice);\n","        cudaFree(d_kernel);\n","    }\n","\n","    // Apply smooth thresholding\n","    applySmoothThreshold<<<blocks, threads>>>(d_output, d_blurred, width, height, adaptiveThreshold);\n","    cudaMemcpy(dest, d_blurred, imageSize, cudaMemcpyDeviceToHost);\n","\n","    // Save final processed frame for debugging\n","    cv::Mat finalFrame(height, width, CV_32F, dest);\n","    finalFrame.convertTo(finalFrame, CV_8U, 255.0);\n","    //cv::imwrite(\"debug_final_frame_\" + std::to_string(frameCount) + \".png\", finalFrame);\n","\n","    // Free device memory\n","    cudaFree(d_original);\n","    cudaFree(d_blurred);\n","    cudaFree(d_temp);\n","    cudaFree(d_output);\n","}\n","\n","int main() {\n","    // Input video file\n","    std::string inputFile = \"test.mp4\";\n","\n","    // OpenCV video capture\n","    cv::VideoCapture cap(inputFile);\n","    if (!cap.isOpened()) {\n","        std::cerr << \"Error: Cannot open video file: \" << inputFile << std::endl;\n","        return -1;\n","    }\n","\n","    // Video properties\n","    int width = static_cast<int>(cap.get(cv::CAP_PROP_FRAME_WIDTH));\n","    int height = static_cast<int>(cap.get(cv::CAP_PROP_FRAME_HEIGHT));\n","    int fps = static_cast<int>(cap.get(cv::CAP_PROP_FPS));\n","\n","    // Output video writer\n","    cv::VideoWriter writer(\"output_video.avi\", cv::VideoWriter::fourcc('M', 'J', 'P', 'G'), fps, cv::Size(width, height), false);\n","\n","    if (!writer.isOpened()) {\n","        std::cerr << \"Error: Cannot open video writer!\" << std::endl;\n","        return -1;\n","    }\n","\n","    cv::Mat frame, grayFrame;\n","    std::vector<float> src, dest(width * height, 0.0f);\n","    int frameCount = 0;\n","\n","    while (true) {\n","        // Capture a frame\n","        cap >> frame;\n","        if (frame.empty()) break;  // Exit if no more frames\n","\n","        frameCount++;\n","\n","        // Convert to grayscale and normalize\n","        cv::cvtColor(frame, grayFrame, cv::COLOR_BGR2GRAY);\n","        grayFrame.convertTo(grayFrame, CV_32F, 1.0 / 255.0);\n","\n","        // Verify normalization\n","        double minVal, maxVal;\n","        cv::minMaxLoc(grayFrame, &minVal, &maxVal);\n","        //std::cout << \"Input Frame \" << frameCount << \" range: [\" << minVal << \", \" << maxVal << \"]\" << std::endl;\n","\n","        // Save normalized input frame for debugging\n","        // cv::imwrite(\"debug_input_frame_\" + std::to_string(frameCount) + \".png\", grayFrame);\n","\n","        // Flatten the frame for CUDA processing\n","        src.assign((float*)grayFrame.datastart, (float*)grayFrame.dataend);\n","\n","        // Calculate adaptive threshold based on mean intensity\n","        float adaptiveThreshold = cv::mean(grayFrame)[0] * 0.3f;\n","\n","        // Process the frame with CUDA\n","        processFrame(src.data(), dest.data(), width, height, 7, frameCount, adaptiveThreshold);\n","\n","        // Reshape and scale back to 8-bit\n","        cv::Mat outputFrame(height, width, CV_32F, dest.data());\n","        outputFrame.convertTo(outputFrame, CV_8U, 255.0);\n","\n","        // Write to video file\n","        writer.write(outputFrame);\n","\n","        // Display the processed frame\n","        // cv::imshow(\"Illustration Effect\", outputFrame);\n","        // if (cv::waitKey(1) == 27) break;  // Exit on 'Esc' key\n","    }\n","\n","    cap.release();\n","    writer.release();\n","    cv::destroyAllWindows();\n","\n","    std::cout << \"Video processing complete!\" << std::endl;\n","    return 0;\n","}\n","'''\n","\n","\n","with open('video_illustration_full.cu', 'w') as file:\n","    file.write(cuda_code)\n"],"metadata":{"id":"gaISe4GoLJQ1","executionInfo":{"status":"ok","timestamp":1733761022485,"user_tz":300,"elapsed":2,"user":{"displayName":"Tanvi Virappa Patil","userId":"04359576273509452367"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!nvcc video_illustration_full.cu -o video_illustration_full `pkg-config --cflags --libs opencv4`"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jy75JfjpLpdQ","executionInfo":{"status":"ok","timestamp":1733761030631,"user_tz":300,"elapsed":8148,"user":{"displayName":"Tanvi Virappa Patil","userId":"04359576273509452367"}},"outputId":"f60fb6ef-2f0c-4dac-fcaa-f7c3e84c2ca7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::buildMaps\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n","  class AffineWarper : public PlaneWarper\n","        ^\n","\n","\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::warp\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n","  class AffineWarper : public PlaneWarper\n","        ^\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(100)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::FeatherBlender\"\u001b[0m\n","  class FeatherBlender : public Blender\n","        ^\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(127)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::MultiBandBlender\"\u001b[0m\n","  class MultiBandBlender : public Blender\n","        ^\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::buildMaps\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n","  class AffineWarper : public PlaneWarper\n","        ^\n","\n","\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/warpers.hpp(235)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::PlaneWarper::warp\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::AffineWarper\"\u001b[0m\n","  class AffineWarper : public PlaneWarper\n","        ^\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(100)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::FeatherBlender\"\u001b[0m\n","  class FeatherBlender : public Blender\n","        ^\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/include/opencv4/opencv2/stitching/detail/blenders.hpp(127)\u001b[0m: \u001b[01;35mwarning\u001b[0m #611-D: overloaded virtual function \u001b[01m\"cv::detail::Blender::prepare\"\u001b[0m is only partially overridden in class \u001b[01m\"cv::detail::MultiBandBlender\"\u001b[0m\n","  class MultiBandBlender : public Blender\n","        ^\n","\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7uHnfbBYkJOh","executionInfo":{"status":"ok","timestamp":1733761031599,"user_tz":300,"elapsed":971,"user":{"displayName":"Tanvi Virappa Patil","userId":"04359576273509452367"}},"outputId":"0a1811cd-e704-4cdb-e41b-1a3e16eafecb"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!./video_illustration_full"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AzJy49tpL462","executionInfo":{"status":"ok","timestamp":1733761033954,"user_tz":300,"elapsed":2356,"user":{"displayName":"Tanvi Virappa Patil","userId":"04359576273509452367"}},"outputId":"1598c6d2-d6ff-4c41-aaf1-c6fd65e63b7a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Video processing complete!\n"]}]}]}